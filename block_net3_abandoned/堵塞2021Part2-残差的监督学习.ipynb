{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9427eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "本节内容：\n",
    "将所有样本（变量：堵塞位置、堵塞大小、用水需求）一起训练，标签为堵塞的管道。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf2c529",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "from torch.optim import Adam,AdamW\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch.utils.data import DataLoader\n",
    "from prefetch_generator import BackgroundGenerator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt \n",
    "import hiddenlayer as hl\n",
    "from sklearn.model_selection import train_test_split,StratifiedKFold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import QuantileTransformer,RobustScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import lightgbm as lgb\n",
    "#准备文件夹保存数据\n",
    "local_path=os.getcwd()\n",
    "if not os.path.exists(local_path+'\\\\blokagedata'):\n",
    "    os.mkdir(local_path+'\\\\blokagedata')\n",
    "print(local_path+'\\\\blokagedata')\n",
    "#判断是否可以使用GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426db555",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import train_test_split,RandomizedSearchCV,GridSearchCV,StratifiedKFold,cross_validate\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scipy.stats import loguniform,uniform,randint\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#准备文件夹保存数据\n",
    "local_path=os.getcwd()\n",
    "if not os.path.exists(local_path+'\\\\blokagedata'):\n",
    "    os.mkdir(local_path+'\\\\blokagedata')\n",
    "print(local_path+'\\\\blokagedata')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12cbe83",
   "metadata": {},
   "source": [
    "# ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7208c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoaderX(DataLoader):\n",
    "    def __iter__(self):\n",
    "        return BackgroundGenerator(super().__iter__())\n",
    "#ANN\n",
    "class ANN(nn.Module):\n",
    "    def __init__(self,d1,hidden_size,d2):\n",
    "        super(ANN,self).__init__()\n",
    "        self.ann=nn.Sequential(nn.BatchNorm1d(d1,momentum=0.5),\n",
    "                               nn.Linear(d1,hidden_size),\n",
    "                               nn.LeakyReLU(),\n",
    "                               nn.BatchNorm1d(hidden_size,momentum=0.5),\n",
    "                               nn.Linear(hidden_size,d2),\n",
    "                               nn.LeakyReLU()\n",
    "                              )\n",
    "    def forward(self,x):\n",
    "        x = self.ann(x)\n",
    "        return x\n",
    "#训练模型\n",
    "def anntrain(args):\n",
    "    model=ANN(d1=args['d1'],hidden_size=args['hidden_size'],d2=args['d2']).to(device)\n",
    "    criterion=nn.CrossEntropyLoss().to(device)\n",
    "    optimizer=AdamW(model.parameters(),lr=args['learning_rate'],weight_decay=args['weight_decay'])\n",
    "    scheduler=LambdaLR(optimizer,verbose=False,lr_lambda=lambda epoch:1/(epoch/100+1))\n",
    "    train_loader=DataLoader(dataset=train_data,batch_size=len(x_train),\n",
    "                                  shuffle=True,num_workers=0)\n",
    "    history1=hl.History()\n",
    "    canvas1=hl.Canvas()\n",
    "    best_acc=0\n",
    "    for epoch in tqdm(range(args['epoches'])):\n",
    "        for step,(batch_x,batch_y) in enumerate(train_loader):\n",
    "            #输出层与标签之间的误差    \n",
    "            model.train()\n",
    "            prediction=model(batch_x)\n",
    "            loss=criterion(prediction,batch_y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            #记录误差曲线和acc曲线\n",
    "            steps=epoch*len(train_loader)+step+1\n",
    "            if steps%25==0:\n",
    "                test_acc=score_model(x_test_tensor,y_test_tensor,model)\n",
    "                best_acc=test_acc if test_acc>best_acc else best_acc\n",
    "                history1.log(steps,train_loss=loss.item(),test_accuracy=test_acc)\n",
    "        scheduler.step()\n",
    "    with canvas1:\n",
    "        canvas1.draw_plot(history1['train_loss'])\n",
    "        canvas1.draw_plot(history1['test_accuracy'])\n",
    "    print('train_loss:%.4f'%loss.item())\n",
    "    print('test_acc:%.4f'%test_acc)\n",
    "    print('best_acc:%.4f'%best_acc)\n",
    "    return model,best_acc\n",
    "#测试数据\n",
    "def run_model(data,model):\n",
    "    model.eval()\n",
    "    torch.no_grad()\n",
    "    prediction=model(data)\n",
    "    return prediction.detach()\n",
    "def score_model(x_tensor,label_tensor,model):\n",
    "    x=run_model(x_tensor,model)\n",
    "    x=torch.argmax(x,1).unsqueeze(1)\n",
    "    score=(x==label_tensor).sum().item()/len(x)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3484244b",
   "metadata": {},
   "source": [
    "## 模型寻优"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474ba6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取模型数据\n",
    "sample=pd.read_csv(local_path+'\\\\blokagedata\\\\Sample_116.csv',header=0)\n",
    "#划分样本和标签\n",
    "x=np.array(sample.iloc[:,range(0,96)])#.astype(int)\n",
    "y=np.array(sample.loc[:,'code']).reshape(-1,1).astype(int)\n",
    "#训练模型\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5,shuffle=True,random_state=1)\n",
    "score_record=[]\n",
    "hs_record=[]\n",
    "for hs in range(100,300,10):\n",
    "    params={\n",
    "    \"d1\":96,\n",
    "    \"hidden_size\": hs,\n",
    "    \"d2\":116,\n",
    "    \"learning_rate\":0.01,\n",
    "    \"epoches\":1500,\n",
    "    \"weight_decay\":0.01\n",
    "    }\n",
    "    acc=[]\n",
    "    for train_index, test_index in skf.split(x,y):\n",
    "        x_train, x_test = x[train_index], x[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        #qt\n",
    "        qt = QuantileTransformer(output_distribution = 'uniform' )\n",
    "        x_train = qt.fit_transform(x_train)\n",
    "        x_test = qt.transform(x_test)\n",
    "        #numpy转为张量\n",
    "        x_train_tensor=torch.from_numpy(x_train).float().to(device)\n",
    "        y_train_tensor=torch.from_numpy(y_train).to(device)\n",
    "        x_test_tensor=torch.from_numpy(x_test).float().to(device)\n",
    "        y_test_tensor=torch.from_numpy(y_test).to(device)\n",
    "        train_data=Data.TensorDataset(x_train_tensor,y_train_tensor.long().squeeze())\n",
    "        annmodel,best_acc=anntrain(params)\n",
    "        train_acc=score_model(x_train_tensor,y_train_tensor,annmodel)\n",
    "        print('train_acc:',train_acc)\n",
    "        acc.append(best_acc)\n",
    "        print('acc:',acc)\n",
    "    ave_score=np.mean(acc)\n",
    "    print('ave_acc',ave_score)\n",
    "    score_record.append(ave_score)\n",
    "    hs_record.append(hs)\n",
    "    print('score_record:',score_record)\n",
    "    print('hs_record:',hs_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8f9758",
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取模型数据\n",
    "sample=pd.read_csv(local_path+'\\\\blokagedata\\\\Sample_116_percent.csv',header=0)\n",
    "#划分样本和标签\n",
    "x=np.array(sample.iloc[:,range(0,96)])#.astype(int)\n",
    "y=np.array(sample.loc[:,'code']).reshape(-1,1).astype(int)\n",
    "#训练模型\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5,shuffle=True,random_state=1)\n",
    "\n",
    "params={\n",
    "\"d1\":96,\n",
    "\"hidden_size\": 110,\n",
    "\"d2\":116,\n",
    "\"learning_rate\":0.01,\n",
    "\"epoches\":1500,\n",
    "\"weight_decay\":0.01\n",
    "}\n",
    "acc=[]\n",
    "for train_index, test_index in skf.split(x,y):\n",
    "    x_train, x_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    #qt\n",
    "    qt = QuantileTransformer(output_distribution = 'uniform' )\n",
    "    x_train = qt.fit_transform(x_train)\n",
    "    x_test = qt.transform(x_test)\n",
    "    #numpy转为张量\n",
    "    x_train_tensor=torch.from_numpy(x_train).float().to(device)\n",
    "    y_train_tensor=torch.from_numpy(y_train).to(device)\n",
    "    x_test_tensor=torch.from_numpy(x_test).float().to(device)\n",
    "    y_test_tensor=torch.from_numpy(y_test).to(device)\n",
    "    train_data=Data.TensorDataset(x_train_tensor,y_train_tensor.long().squeeze())\n",
    "    annmodel,best_acc=anntrain(params)\n",
    "    train_acc=score_model(x_train_tensor,y_train_tensor,annmodel)\n",
    "    print('train_acc:',train_acc)\n",
    "    acc.append(best_acc)\n",
    "    print('acc:',acc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1538a1",
   "metadata": {},
   "source": [
    "## 处理结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f890a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(annmodel.state_dict(),local_path+'\\\\blokagedata\\\\annmodel_hid110.pkl')\n",
    "# model = TheModelClass(...)\n",
    "# model.load_state_dict(torch.load('\\parameter.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b76412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = TheModelClass(...)\n",
    "# model.load_state_dict(torch.load('\\parameter.pkl'))\n",
    "pre=run_model(x_test_tensor,annmodel)\n",
    "pre=torch.argmax(pre,1).unsqueeze(1).cpu().numpy()\n",
    "bool1=np.ones([len(pre),1])\n",
    "bool1[np.where(pre.ravel()!=y_test.ravel())]=0\n",
    "pred=pd.DataFrame(pre)\n",
    "S=sample.loc[test_index,:]\n",
    "para=S.iloc[:,range(96,99)].reset_index()\n",
    "bool2=pd.DataFrame(bool1.astype(int))\n",
    "a=pd.concat([pred,para,bool2],axis=1,ignore_index=True)\n",
    "a.columns=['pred','index','true','dn','time','bool']\n",
    "a=a[['index','pred','true','dn','time','bool']]\n",
    "a.to_csv(local_path+'\\\\blokagedata\\\\ann_hid110_test_result.csv',encoding='ascii',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7e7411",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "cm=pd.DataFrame(confusion_matrix(y_test.ravel(),pre))\n",
    "cm.to_csv(local_path+'\\\\blokagedata\\\\ann_hid110_cm.csv',encoding='ascii',index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd7c000",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04208c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取模型数据\n",
    "sample=pd.read_csv(local_path+'\\\\blokagedata\\\\Sample_116.csv',header=0)\n",
    "#划分样本和标签\n",
    "x=np.array(sample.iloc[:,range(0,96)])#.astype(int)\n",
    "y=np.array(sample.loc[:,'code']).reshape(-1,1).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6eefe17",
   "metadata": {},
   "source": [
    "## 模型寻优"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db2c0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('scaler', QuantileTransformer(output_distribution = 'uniform')), ('svc', SVC(decision_function_shape='ovr',kernel='rbf'))])\n",
    "param_dist = {'svc__C': [1,10,100,1000,10000,100000,500000,800000,1000000,1200000,1500000],\n",
    " 'svc__gamma': [0.01,0.02,0.03,0.04,0.05,0.06,0.07,0.08,0.09,0.01]}\n",
    "splitter=StratifiedKFold(n_splits=5,random_state=1,shuffle=True)\n",
    "clf = GridSearchCV(estimator=pipe,param_grid=param_dist,cv=splitter,n_jobs=-1,scoring='accuracy',verbose=3)\n",
    "search = clf.fit(x, y.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20986d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('网格搜索-度量记录：',search.cv_results_)  # 包含每次训练的相关信息\n",
    "print('网格搜索-最佳度量值:',search.best_score_)  # 获取最佳度量值\n",
    "print('网格搜索-最佳参数：',search.best_params_)  # 获取最佳度量值时的代定参数的值。是一个字典\n",
    "print('网格搜索-最佳模型：',search.best_estimator_)  # 获取最佳度量时的分类器模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbede1a",
   "metadata": {},
   "source": [
    "## 处理结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342ad085",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx=search.cv_results_['param_svc__C'].data.astype(float)\n",
    "yy=search.cv_results_['param_svc__gamma'].data.astype(float)\n",
    "zz=search.cv_results_['mean_test_score'].astype(float)\n",
    "xx=np.expand_dims(xx,axis=1)\n",
    "yy=np.expand_dims(yy,axis=1)\n",
    "zz=np.expand_dims(zz,axis=1)\n",
    "print(xx.shape)\n",
    "print(yy.shape)\n",
    "print(zz.shape)\n",
    "zxc=pd.DataFrame(np.hstack((xx,yy,zz)))\n",
    "zxc.columns=['C','gamma','acc']\n",
    "zxc=pd.pivot_table(zxc,index=['C'],columns=['gamma'],values=['acc'])\n",
    "zxc.to_csv(local_path+'\\\\blokagedata\\\\svm_finetune_grid_b.csv',encoding='ascii',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e96b2fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28ad10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=123,stratify=y)\n",
    "best_clf=search.best_estimator_\n",
    "y_pre=best_clf.predict(x_test)\n",
    "cm=pd.DataFrame(confusion_matrix(y_test.ravel(),y_pre))\n",
    "cm.to_csv(local_path+'\\\\blokagedata\\\\svm_cm.csv',encoding='ascii',index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bebb2c",
   "metadata": {},
   "source": [
    "# RF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03470ed4",
   "metadata": {},
   "source": [
    "## 模型寻优"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4e80a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('scaler', QuantileTransformer(output_distribution = 'uniform')), ('rfc', RandomForestClassifier(criterion='gini',))])\n",
    "param_dist = {'rfc__n_estimators': randint(10, 500),\n",
    " 'rfc__min_samples_split': randint(2, 1000),\n",
    " 'rfc__max_depth': randint(2, 100)}\n",
    "splitter=StratifiedKFold(n_splits=5,random_state=1,shuffle=True)\n",
    "clf = RandomizedSearchCV(estimator=pipe,param_distributions=param_dist,n_iter=10,cv=splitter,random_state=11,n_jobs=-1,scoring='accuracy',verbose=3)\n",
    "search = clf.fit(x, y.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28e4edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('网格搜索-度量记录：',search.cv_results_)  # 包含每次训练的相关信息\n",
    "print('网格搜索-最佳度量值:',search.best_score_)  # 获取最佳度量值\n",
    "print('网格搜索-最佳参数：',search.best_params_)  # 获取最佳度量值时的代定参数的值。是一个字典\n",
    "print('网格搜索-最佳模型：',search.best_estimator_)  # 获取最佳度量时的分类器模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36039f2",
   "metadata": {},
   "source": [
    "## 处理结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d684c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1=search.cv_results_['param_rfc__n_estimators'].data.astype(int)\n",
    "q2=search.cv_results_['param_rfc__min_samples_split'].data.astype(int)\n",
    "q3=search.cv_results_['param_rfc__max_depth'].data.astype(int)\n",
    "zz=search.cv_results_['mean_test_score'].astype(float)\n",
    "q1=np.expand_dims(q1,axis=1)\n",
    "q2=np.expand_dims(q2,axis=1)\n",
    "q3=np.expand_dims(q3,axis=1)\n",
    "zz=np.expand_dims(zz,axis=1)\n",
    "print(q1.shape)\n",
    "print(q2.shape)\n",
    "print(q3.shape)\n",
    "print(zz.shape)\n",
    "pd.DataFrame(np.hstack((q1,q2,q3,zz))).to_csv(local_path+'\\\\blokagedata\\\\rfc_finetune.csv',encoding='ascii',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1512ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ave=[]\n",
    "m=[]\n",
    "for n in tqdm(range(50,150,10)):\n",
    "    rfc=RandomForestClassifier(n_estimators=n,criterion='gini',max_depth=None,min_samples_split=2,n_jobs=-1)\n",
    "    scores = cross_validate(rfc, x, y.ravel(), cv=splitter,scoring=('accuracy'),return_train_score=True,n_jobs=-1)\n",
    "    m.append(n)\n",
    "    ave.append(np.mean(scores['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3109eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc=RandomForestClassifier(n_estimators=150,criterion='gini',max_depth=None,min_samples_split=2,n_jobs=-1)\n",
    "rfc.fit(x_train,y_train.ravel())\n",
    "score=rfc.score(x_test,y_test.ravel())\n",
    "print('rfc:',score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7243c34",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb237abd",
   "metadata": {},
   "source": [
    "## 模型寻优"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a0d17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('scaler', QuantileTransformer(output_distribution = 'uniform')), ('knn', KNeighborsClassifier())])\n",
    "param_dist = {'knn__n_neighbors': [1,2,3,4,5,6,7,8,9]}\n",
    "splitter=StratifiedKFold(n_splits=5,random_state=1,shuffle=True)\n",
    "clf = RandomizedSearchCV(estimator=pipe,param_distributions=param_dist,n_iter=9,cv=splitter,random_state=1,n_jobs=-1,scoring='accuracy',verbose=3)\n",
    "search = clf.fit(x, y.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d9a997",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('网格搜索-度量记录：',search.cv_results_)  # 包含每次训练的相关信息\n",
    "print('网格搜索-最佳度量值:',search.best_score_)  # 获取最佳度量值\n",
    "print('网格搜索-最佳参数：',search.best_params_)  # 获取最佳度量值时的代定参数的值。是一个字典\n",
    "print('网格搜索-最佳模型：',search.best_estimator_)  # 获取最佳度量时的分类器模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ae8d10",
   "metadata": {},
   "source": [
    "## 处理结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2dc9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx=search.cv_results_['param_knn__n_neighbors'].data.astype(float)\n",
    "zz=search.cv_results_['mean_test_score'].astype(float)\n",
    "xx=np.expand_dims(xx,axis=1)\n",
    "zz=np.expand_dims(zz,axis=1)\n",
    "print(xx.shape)\n",
    "print(zz.shape)\n",
    "zxc=pd.DataFrame(np.hstack((xx,zz)))\n",
    "zxc.columns=['k','acc']\n",
    "zxc.to_csv(local_path+'\\\\blokagedata\\\\knn_finetune.csv',encoding='ascii',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66040b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=123,stratify=y)\n",
    "knn=KNeighborsClassifier(n_neighbors=1, weights='distance',metric='minkowski', p=2)\n",
    "knn.fit(x_train,y_train.ravel())\n",
    "score=knn.score(x_test,y_test.ravel())\n",
    "print('knn:',score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
