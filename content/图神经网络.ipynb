{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203768b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-25T13:08:01.044365Z",
     "start_time": "2021-12-25T13:07:23.717075Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# import torch.utils.data as Data,DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from prefetch_generator import BackgroundGenerator\n",
    "\n",
    "import torch_geometric.nn as gnn\n",
    "import torch_geometric.data as gdata\n",
    "import torch_geometric.nn.models as gmodel\n",
    "from torch_geometric.data import Data,DataLoader\n",
    "from torch_geometric.nn import GraphConv, TopKPooling\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import hiddenlayer as hl\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#准备文件夹保存数据\n",
    "local_path=os.getcwd()\n",
    "if not os.path.exists(local_path+'\\\\blokagedata'):\n",
    "    os.mkdir(local_path+'\\\\blokagedata')\n",
    "print(local_path+'\\\\blokagedata')\n",
    "#判断是否可以使用GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d2f683",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T11:11:22.818919Z",
     "start_time": "2021-07-29T11:11:22.811938Z"
    }
   },
   "outputs": [],
   "source": [
    "class DataLoaderX(DataLoader):\n",
    "    def __iter__(self):\n",
    "        return BackgroundGenerator(super().__iter__())\n",
    "def run_model(batch,model):\n",
    "    model.eval()\n",
    "    torch.no_grad()\n",
    "    prediction=model(batch)\n",
    "    return prediction.detach()\n",
    "def score_model(batch,model):\n",
    "    x=run_model(batch,model)\n",
    "    x=torch.argmax(x,1)\n",
    "    score=(x==batch.y).sum().item()/len(x)\n",
    "    return round(score,4)\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = gnn.GATConv(1, 1,heads=3)\n",
    "#         self.conv2 = gnn.GCNConv(3, 3)\n",
    "#         self.conv3 = gnn.SAGEConv(1, 1)\n",
    "#         self.pool1 = TopKPooling(100, ratio=0.4)\n",
    "#         self.pool2 = TopKPooling(100, ratio=0.4)\n",
    "        self.lin1 = nn.Linear(96*3, 200)\n",
    "        self.lin2 = nn.Linear(200, 117)\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "#         x, edge_index, _, batch, _, _ = self.pool1(x, edge_index, None, batch)\n",
    "#         x1 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "#         x = F.relu(self.conv2(x, edge_index))\n",
    "#         x, edge_index, _, batch, _, _ = self.pool2(x, edge_index, None, batch)\n",
    "#         x2 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "#         x= x1 + x2\n",
    "#         x = F.relu(self.conv2(x, edge_index))\n",
    "#         x = F.relu(self.conv3(x, edge_index))\n",
    "#         x = torch.mean(x,1)\n",
    "        x = x.reshape([int(len(x)/96),96*3])\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = F.relu(self.lin2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ecf273",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T11:11:30.445387Z",
     "start_time": "2021-07-29T11:11:24.258926Z"
    }
   },
   "outputs": [],
   "source": [
    "traindata=pd.read_csv(local_path+'\\\\blokagedata\\\\sample_117.csv',header=0).iloc[:,range(633,729)]\n",
    "trainlabel=np.array(pd.read_csv(local_path+'\\\\blokagedata\\\\y_117.csv',header=0)).astype(int)\n",
    "edge_index=pd.read_excel(local_path+'\\\\blokagedata\\\\edge_index.xls',header=0)\n",
    "x_train,x_test,y_train,y_test=train_test_split(traindata,trainlabel,test_size=0.2,random_state=1,stratify=trainlabel)\n",
    "scaler=MinMaxScaler()\n",
    "x_train=scaler.fit_transform(x_train).T\n",
    "x_test=scaler.transform(x_test).T\n",
    "e=np.array(edge_index).astype(int).T\n",
    "train_list=[]\n",
    "for i in range(len(y_train)):\n",
    "    X=torch.tensor(x_train[:,i]).unsqueeze(1).float()\n",
    "    Y=torch.tensor(y_train[i,0]).long()\n",
    "    E=torch.tensor(e).long()\n",
    "    data = Data(x=X, edge_index=E,y=Y)\n",
    "    train_list.append(data)\n",
    "train_loader= DataLoader(train_list, batch_size=round(len(y_train)*1), shuffle=True)#round(len(y_train)*0.25)\n",
    "test_list=[]\n",
    "for i in range(len(y_test)):\n",
    "    X=torch.tensor(x_test[:,i]).unsqueeze(1).float()\n",
    "    Y=torch.tensor(y_test[i,0]).long()\n",
    "    E=torch.tensor(e).long()\n",
    "    data = Data(x=X, edge_index=E,y=Y)\n",
    "    test_list.append(data)\n",
    "test_loader= DataLoader(test_list, batch_size=len(y_test), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a515692f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T12:26:03.153122Z",
     "start_time": "2021-07-29T11:11:31.458140Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Net().to(device)\n",
    "criterion=nn.CrossEntropyLoss().to(device)\n",
    "optimizer = Adam(model.parameters(), lr=0.0001,weight_decay=0.001)\n",
    "# scheduler=LambdaLR(optimizer,verbose=False,lr_lambda=lambda i:1/(i/750+1))\n",
    "acc=0\n",
    "i=0\n",
    "while acc<100.0 :\n",
    "    i+=1\n",
    "    for one_train_batch in train_loader:\n",
    "        one_train_batch=one_train_batch.to(device)\n",
    "        model.train()\n",
    "        prediction = model(one_train_batch)\n",
    "        loss =criterion(prediction, one_train_batch.y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#     scheduler.step()\n",
    "    for test_batch in test_loader:\n",
    "        test_batch=test_batch.to(device)\n",
    "        acc=round(score_model(test_batch,model),4)*100\n",
    "    print (\"epoch: {}\\t, loss: {:.6f}, test_acc: {}%\".format(i, loss.item(), acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
